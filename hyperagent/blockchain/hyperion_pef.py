"""Hyperion Parallel Execution Framework (PEF) Manager

Concept: Leverage Hyperion's Block-STM for parallel contract deployments
Logic: Analyze dependencies, group independent contracts, deploy in parallel
Benefits: 10-50x faster batch deployments via parallel execution
"""
import asyncio
import logging
import re
from typing import Dict, Any, List, Optional
from datetime import datetime
from collections import defaultdict

from hyperagent.blockchain.networks import NetworkManager
from hyperagent.core.services.deployment_service import DeploymentService

logger = logging.getLogger(__name__)


class HyperionPEFManager:
    """
    Parallel Execution Framework Manager for Hyperion
    
    Concept: Leverage Hyperion's Block-STM for parallel deployments
    Logic:
        1. Analyze contract dependencies (imports, external calls)
        2. Group independent contracts for parallel execution
        3. Deploy in parallel batches using asyncio.gather
        4. Handle transaction conflicts automatically via Block-STM
        5. Return batch results with success/failure status
    """
    
    def __init__(self, network_manager: NetworkManager):
        """
        Initialize PEF Manager
        
        Args:
            network_manager: NetworkManager instance for Web3 operations
        """
        self.network_manager = network_manager
    
    async def analyze_dependencies(
        self, 
        contracts: List[Dict[str, Any]]
    ) -> Dict[str, List[str]]:
        """
        Analyze contract dependencies to determine parallelization
        
        Concept: Parse Solidity code to detect dependencies
        Logic:
            1. Extract import statements
            2. Detect external contract calls
            3. Build dependency graph
            4. Return dependency map
        
        Args:
            contracts: List of contract dictionaries with source_code or compiled_contract
        
        Returns:
            Dictionary mapping contract_name -> list of dependencies
        """
        dependencies = {}
        
        for contract in contracts:
            contract_name = contract.get("contract_name", f"contract_{len(dependencies)}")
            source_code = contract.get("source_code", "")
            
            # If no source code, try to extract from compiled contract
            if not source_code and "compiled_contract" in contract:
                # For compiled contracts, we can't analyze dependencies easily
                # Assume no dependencies (safe for parallel execution)
                dependencies[contract_name] = []
                continue
            
            deps = []
            
            # Extract import statements
            import_pattern = r'import\s+["\']([^"\']+)["\']'
            imports = re.findall(import_pattern, source_code)
            
            # Extract contract/library references
            contract_ref_pattern = r'(?:contract|library|interface)\s+(\w+)'
            contract_refs = re.findall(contract_ref_pattern, source_code)
            
            # Extract external calls (simplified - looks for .call, .delegatecall, etc.)
            external_call_pattern = r'(\w+)\.(call|delegatecall|staticcall|transfer|send)'
            external_calls = re.findall(external_call_pattern, source_code)
            
            # Combine all dependencies
            deps.extend(imports)
            deps.extend(contract_refs)
            deps.extend([call[0] for call in external_calls])
            
            # Remove duplicates and self-references
            deps = list(set([d for d in deps if d != contract_name]))
            dependencies[contract_name] = deps
        
        logger.info(f"Analyzed dependencies for {len(contracts)} contracts")
        return dependencies
    
    def _group_parallel_contracts(
        self,
        contracts: List[Dict[str, Any]],
        dependencies: Dict[str, List[str]]
    ) -> List[List[Dict[str, Any]]]:
        """
        Group contracts into parallel execution batches
        
        Concept: Topological sort to determine execution order
        Logic:
            1. Contracts with no dependencies can run in parallel
            2. Contracts with dependencies must wait for dependencies
            3. Group into batches for parallel execution
        
        Returns:
            List of batches, each batch contains contracts that can run in parallel
        """
        # Build dependency graph
        graph = defaultdict(set)
        in_degree = defaultdict(int)
        contract_map = {c.get("contract_name", f"contract_{i}"): c for i, c in enumerate(contracts)}
        
        for contract_name, deps in dependencies.items():
            in_degree[contract_name] = len(deps)
            for dep in deps:
                graph[dep].add(contract_name)
        
        # Topological sort to create batches
        batches = []
        remaining = set(contract_map.keys())
        
        while remaining:
            # Find contracts with no dependencies (can run in parallel)
            ready = [name for name in remaining if in_degree[name] == 0]
            
            if not ready:
                # Circular dependency or missing dependency
                logger.warning(f"Circular dependency detected or missing dependencies for: {remaining}")
                # Add remaining contracts to a batch anyway (let Block-STM handle conflicts)
                ready = list(remaining)
            
            # Create batch with ready contracts
            batch = [contract_map[name] for name in ready]
            batches.append(batch)
            
            # Update in-degrees for next iteration
            for name in ready:
                remaining.remove(name)
                for dependent in graph[name]:
                    in_degree[dependent] -= 1
        
        logger.info(f"Grouped {len(contracts)} contracts into {len(batches)} parallel batches")
        return batches
    
    async def deploy_batch(
        self,
        contracts: List[Dict[str, Any]],
        network: str = "hyperion_testnet",
        max_parallel: int = 10,
        private_key: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Deploy multiple contracts in parallel using Hyperion PEF
        
        Concept: Use Block-STM for parallel execution
        Logic:
            1. Analyze dependencies
            2. Group into parallel batches
            3. Deploy each batch in parallel
            4. Aggregate results
        
        Args:
            contracts: List of contract dictionaries
            network: Target network (must be Hyperion)
            max_parallel: Maximum parallel deployments per batch
            private_key: Private key for deployment
        
        Returns:
            {
                "success": bool,
                "deployments": [
                    {
                        "contract_name": str,
                        "contract_address": str,
                        "transaction_hash": str,
                        "status": "success" | "failed",
                        "error": Optional[str]
                    }
                ],
                "total_time": float,
                "parallel_count": int
            }
        """
        # Check feature availability with graceful fallback
        from hyperagent.blockchain.network_features import (
            NetworkFeatureManager,
            NetworkFeature
        )
        
        if not NetworkFeatureManager.supports_feature(network, NetworkFeature.PEF):
            logger.warning(
                f"PEF not available for {network}. "
                f"Falling back to sequential deployment."
            )
            # Fallback to sequential deployment
            return await self._deploy_sequential_fallback(
                contracts, network, max_parallel, private_key
            )
        
        start_time = datetime.now()
        
        # Analyze dependencies
        dependencies = await self.analyze_dependencies(contracts)
        
        # Group into parallel batches
        batches = self._group_parallel_contracts(contracts, dependencies)
        
        # Initialize deployment service
        from hyperagent.blockchain.alith_client import AlithClient
        from hyperagent.blockchain.eigenda_client import EigenDAClient
        from hyperagent.core.config import settings
        
        alith_client = AlithClient()
        eigenda_client = EigenDAClient(
            disperser_url=settings.eigenda_disperser_url,
            private_key=private_key or settings.private_key,
            use_authenticated=settings.eigenda_use_authenticated
        )
        
        deployment_service = DeploymentService(
            network_manager=self.network_manager,
            alith_client=alith_client,
            eigenda_client=eigenda_client,
            use_alith_autonomous=False
        )
        
        all_deployments = []
        parallel_count = 0
        
        # Deploy each batch
        for batch_index, batch in enumerate(batches):
            logger.info(f"Deploying batch {batch_index + 1}/{len(batches)} with {len(batch)} contracts")
            
            # Limit parallel deployments per batch
            batch_limited = batch[:max_parallel]
            
            # Deploy contracts in parallel
            deployment_tasks = []
            for contract in batch_limited:
                task = self._deploy_single_contract(
                    deployment_service,
                    contract,
                    network,
                    private_key
                )
                deployment_tasks.append(task)
            
            # Wait for all deployments in batch
            batch_results = await asyncio.gather(*deployment_tasks, return_exceptions=True)
            
            # Process results
            for contract, result in zip(batch_limited, batch_results):
                contract_name = contract.get("contract_name", "unknown")
                
                if isinstance(result, Exception):
                    all_deployments.append({
                        "contract_name": contract_name,
                        "status": "failed",
                        "error": str(result),
                        "contract_address": None,
                        "transaction_hash": None
                    })
                else:
                    if result.get("status") == "success":
                        all_deployments.append({
                            "contract_name": contract_name,
                            "status": "success",
                            "contract_address": result.get("contract_address"),
                            "transaction_hash": result.get("transaction_hash"),
                            "block_number": result.get("block_number"),
                            "gas_used": result.get("gas_used"),
                            "error": None
                        })
                        parallel_count += 1
                    else:
                        all_deployments.append({
                            "contract_name": contract_name,
                            "status": "failed",
                            "error": result.get("error", "Unknown error"),
                            "contract_address": None,
                            "transaction_hash": None
                        })
        
        end_time = datetime.now()
        total_time = (end_time - start_time).total_seconds()
        
        success_count = len([d for d in all_deployments if d["status"] == "success"])
        
        return {
            "success": success_count > 0,
            "deployments": all_deployments,
            "total_time": total_time,
            "parallel_count": parallel_count,
            "success_count": success_count,
            "failed_count": len(all_deployments) - success_count,
            "batches_deployed": len(batches)
        }
    
    async def _deploy_single_contract(
        self,
        deployment_service: DeploymentService,
        contract: Dict[str, Any],
        network: str,
        private_key: Optional[str]
    ) -> Dict[str, Any]:
        """
        Deploy a single contract using deployment service
        
        Args:
            deployment_service: DeploymentService instance
            contract: Contract dictionary
            network: Target network
            private_key: Private key for deployment
        
        Returns:
            Deployment result dictionary
        """
        try:
            compiled = contract.get("compiled_contract")
            if not compiled:
                raise ValueError("compiled_contract is required")
            
            input_data = {
                "compiled_contract": compiled,
                "network": network,
                "private_key": private_key
            }
            
            result = await deployment_service.process(input_data)
            return result
            
        except Exception as e:
            logger.error(f"Failed to deploy contract {contract.get('contract_name', 'unknown')}: {e}")
            raise
    
    async def _deploy_sequential_fallback(
        self,
        contracts: List[Dict[str, Any]],
        network: str,
        max_parallel: int,
        private_key: Optional[str]
    ) -> Dict[str, Any]:
        """
        Sequential deployment fallback when PEF is not available
        
        Concept: Deploy contracts one by one when parallel execution is not supported
        Logic:
            1. Deploy contracts sequentially
            2. Track success/failure for each
            3. Return aggregated results
        
        Args:
            contracts: List of contract dictionaries
            network: Target network
            max_parallel: Ignored (sequential deployment)
            private_key: Private key for deployment
        
        Returns:
            Same format as deploy_batch() but with sequential execution
        """
        from hyperagent.core.services.deployment_service import DeploymentService
        from hyperagent.blockchain.alith_client import AlithClient
        from hyperagent.blockchain.eigenda_client import EigenDAClient
        from hyperagent.core.config import settings
        
        start_time = datetime.now()
        
        # Initialize deployment service
        alith_client = AlithClient()
        eigenda_client = EigenDAClient(
            disperser_url=settings.eigenda_disperser_url,
            private_key=private_key or settings.private_key,
            use_authenticated=settings.eigenda_use_authenticated
        )
        
        deployment_service = DeploymentService(
            network_manager=self.network_manager,
            alith_client=alith_client,
            eigenda_client=eigenda_client,
            use_alith_autonomous=False
        )
        
        all_deployments = []
        success_count = 0
        
        # Deploy contracts sequentially
        for contract in contracts:
            contract_name = contract.get("contract_name", "unknown")
            logger.info(f"Deploying contract {contract_name} sequentially...")
            
            try:
                result = await self._deploy_single_contract(
                    deployment_service,
                    contract,
                    network,
                    private_key
                )
                
                if result.get("status") == "success":
                    all_deployments.append({
                        "contract_name": contract_name,
                        "status": "success",
                        "contract_address": result.get("contract_address"),
                        "transaction_hash": result.get("transaction_hash"),
                        "block_number": result.get("block_number"),
                        "gas_used": result.get("gas_used"),
                        "error": None
                    })
                    success_count += 1
                else:
                    all_deployments.append({
                        "contract_name": contract_name,
                        "status": "failed",
                        "error": result.get("error", "Unknown error"),
                        "contract_address": None,
                        "transaction_hash": None
                    })
            except Exception as e:
                all_deployments.append({
                    "contract_name": contract_name,
                    "status": "failed",
                    "error": str(e),
                    "contract_address": None,
                    "transaction_hash": None
                })
        
        end_time = datetime.now()
        total_time = (end_time - start_time).total_seconds()
        
        return {
            "success": success_count > 0,
            "deployments": all_deployments,
            "total_time": total_time,
            "parallel_count": 0,  # Sequential deployment
            "success_count": success_count,
            "failed_count": len(all_deployments) - success_count,
            "batches_deployed": len(contracts),  # Each contract is its own "batch"
            "deployment_method": "sequential_fallback"
        }

