"""Service-Oriented Architecture implementation"""
from typing import Dict, Any, List
from hyperagent.core.agent_system import ServiceInterface


class ServiceRegistry:
    """
    Service Discovery Pattern
    
    Concept: Central registry for service lookup
    Logic: Services register themselves with metadata
    Usage: Orchestrators query registry to find services
    """
    
    def __init__(self):
        self._services: Dict[str, ServiceInterface] = {}
        self._metadata: Dict[str, Dict[str, Any]] = {}
    
    def register(self, name: str, service: ServiceInterface, 
                 metadata: Dict[str, Any] = None):
        """
        Register a service
        
        Example:
            registry.register(
                "generation",
                GenerationService(llm_provider),
                {"version": "1.0", "sla": {"p99": 45000}}
            )
        """
        self._services[name] = service
        self._metadata[name] = metadata or {}
    
    def get_service(self, name: str) -> ServiceInterface:
        """Retrieve service by name (throws if not found)"""
        if name not in self._services:
            raise ValueError(f"Service '{name}' not found")
        return self._services[name]
    
    def list_services(self) -> List[str]:
        """List all registered service names"""
        return list(self._services.keys())


class SequentialOrchestrator:
    """
    Pipeline Pattern - Sequential Execution
    
    Concept: Execute services one after another
    Logic: Output of service N becomes input to service N+1
    Use Case: Workflow stages (Generate → Audit → Test → Deploy)
    """
    
    def __init__(self, registry: ServiceRegistry, event_bus, progress_callback=None):
        self.registry = registry
        self.event_bus = event_bus
        self.progress_callback = progress_callback
    
    async def orchestrate(self, workflow_context: Dict[str, Any]) -> Dict[str, Any]:
        """
        Execute services sequentially
        
        Example Flow:
            Input: {"nlp_description": "Create ERC20 token"}
            Stage 1 (Generation): {"contract_code": "pragma solidity..."}
            Stage 2 (Audit): {"vulnerabilities": [], "risk_score": 10}
            Stage 3 (Testing): {"tests_passed": 10, "coverage": 85}
            Stage 4 (Deploy): {"contract_address": "0x123..."}
        """
        pipeline = workflow_context.get("pipeline", [])
        result = workflow_context.get("initial_data", {})
        
        for stage_index, stage in enumerate(pipeline):
            service_name = stage["service"]
            service = self.registry.get_service(service_name)
            
            # Map previous output to current input
            request = self._map_inputs(stage, result)
            
            # Validate
            if not await service.validate(request):
                raise ValueError(f"Validation failed for {service_name}")
            
            # Execute
            service_result = await service.process(request)
            
            # Merge service result into overall result (preserve previous data)
            # Service-specific keys are stored under service name for clarity
            if isinstance(service_result, dict):
                # Store service result under service name
                result[f"{service_name}_result"] = service_result
                # Also merge top-level keys for backward compatibility
                for key, value in service_result.items():
                    if key not in result or result[key] is None:
                        result[key] = value
                    elif isinstance(result[key], dict) and isinstance(value, dict):
                        # Merge nested dictionaries
                        result[key].update(value)
                    else:
                        # Overwrite if not a dict
                        result[key] = value
            else:
                result[f"{service_name}_result"] = service_result
            
            # Call progress callback if provided
            if self.progress_callback:
                try:
                    # Stage progress mapping (progress percentage)
                    stage_progress_map = {
                        "generation": 20,
                        "compilation": 40,
                        "audit": 60,
                        "testing": 80,
                        "deployment": 100
                    }
                    # Stage status mapping (workflow status enum values)
                    # Note: "compiling" may not be in WorkflowStatus enum, use "generating" as fallback
                    stage_status_map = {
                        "generation": "generating",
                        "compilation": "generating",  # Compilation happens after generation, keep same status
                        "audit": "auditing",
                        "testing": "testing",
                        "deployment": "completed"  # Mark as completed immediately after deployment succeeds
                    }
                    progress = stage_progress_map.get(service_name, 0)
                    status = stage_status_map.get(service_name, service_name)
                    
                    # For deployment, check if it was successful before marking as completed
                    if service_name == "deployment" and isinstance(service_result, dict):
                        if service_result.get("status") == "success":
                            # Deployment succeeded - mark as completed immediately
                            status = "completed"
                            progress = 100
                        else:
                            # Deployment failed - keep as deploying (will be updated to failed later)
                            status = "deploying"
                    
                    await self.progress_callback(status, progress)
                except Exception as e:
                    # Log but don't fail workflow if progress callback fails
                    import logging
                    logger = logging.getLogger(__name__)
                    logger.error(f"Failed to call progress callback: {e}")
            
            # Publish progress event (skip if event_bus is not properly initialized)
            try:
                from hyperagent.events.event_types import Event, EventType
                from datetime import datetime
                import uuid
                
                # Get workflow_id from context if available
                workflow_id = workflow_context.get("initial_data", {}).get("workflow_id", "unknown")
                
                progress_event = Event(
                    id=str(uuid.uuid4()),
                    type=EventType.WORKFLOW_STARTED,  # Use appropriate event type
                    workflow_id=str(workflow_id),
                    timestamp=datetime.now(),
                    data={
                        "stage": stage_index,
                        "service": service_name,
                        "result": service_result
                    },
                    source_agent="orchestrator"
                )
                await self.event_bus.publish(progress_event)
            except Exception as e:
                # Log but don't fail workflow if event publishing fails
                print(f"Failed to publish progress event: {e}")
        
        return result
    
    def _map_inputs(self, stage: Dict, previous_output: Dict) -> Dict:
        """Map previous stage output to current stage input"""
        request = {}
        
        # Static inputs from stage config
        if "inputs" in stage:
            request.update(stage["inputs"])
        
        # Dynamic inputs from previous output
        if "input_mapping" in stage:
            for target_key, source_key in stage["input_mapping"].items():
                if source_key in previous_output:
                    request[target_key] = previous_output[source_key]
        
        return request

